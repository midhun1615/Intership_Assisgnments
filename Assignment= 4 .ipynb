{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7 Scrape the details of Data science recruiters from naukri.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url = https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Designation\n",
    "\n",
    "C) Company\n",
    "\n",
    "D) Skills they hire for\n",
    "\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\91981\\Desktop\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Analyst” in “Skill,Designations,Companies” field\n",
    "search_fields_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_fields_designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Name_tag=[]\n",
    "company_job=[]\n",
    "Designation_job=[]\n",
    "Req_skill=[]\n",
    "loc_job=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist/Analyst - Machine Learning/Deep Learning',\n",
       " 'Data Scientist - Python/ MATLAB/ Machine Learning Algorithms']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Name tag\n",
    "name=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in name:\n",
    "    if i.text is None:\n",
    "        Name_tag.append(\"--\")\n",
    "    else:\n",
    "        Name_tag.append(i.text)\n",
    "Name_tag[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EchoIndia', '(5 Reviews)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Company Name\n",
    "comp=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in comp:\n",
    "    if i.text is None:\n",
    "        company_job.append(\"--\")\n",
    "    else:\n",
    "        company_job.append(i.text)\n",
    "company_job[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist/Analyst - Machine Learning/Deep Learning',\n",
       " 'Data Scientist - Python/ MATLAB/ Machine Learning Algorithms']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping Designation of the job\n",
    "Desg=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in Desg:\n",
    "    if i.text is None:\n",
    "        Designation_job.append(\"--\")\n",
    "    else:\n",
    "        Designation_job.append(i.text)\n",
    "Designation_job[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IT Skills\\nPython\\nMachine Learning\\nTableau\\nPower BI\\nArcGIS\\nGoogle Maps\\nNLP',\n",
       " 'IT Skills\\nPython\\nMachine Learning\\nData Science\\nData Scientist\\nData Mining\\nStatistical Analyst\\nMachine Learning']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping Required _skill\n",
    "skill=driver.find_elements_by_xpath(\"//ul[@class='tags has-description']\")\n",
    "for i in skill:\n",
    "    if i.text is None:\n",
    "        Req_skill.append(\"--\")\n",
    "    else:\n",
    "        Req_skill.append(i.text)\n",
    "Req_skill[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhi', 'Bengaluru']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping location\n",
    "loc=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in loc:\n",
    "    if i.text is None:\n",
    "        loc_job.append(\"--\")\n",
    "    else:\n",
    "        loc_job.append(i.text)\n",
    "loc_job[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing pandas for creating a DataFrame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the DataFrame\n",
    "df=pd.DataFrame({\"Name_tag\":Name_tag[0:5],\"company_job\":company_job[0:5],\"Designation_job\":Designation_job[0:5],\n",
    "                \"Req_skill\":Req_skill[0:5],\"loc_job\":loc_job[0:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name_tag</th>\n",
       "      <th>company_job</th>\n",
       "      <th>Designation_job</th>\n",
       "      <th>Req_skill</th>\n",
       "      <th>loc_job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Analyst - Machine Learning/Deep...</td>\n",
       "      <td>EchoIndia</td>\n",
       "      <td>Data Scientist/Analyst - Machine Learning/Deep...</td>\n",
       "      <td>IT Skills\\nPython\\nMachine Learning\\nTableau\\n...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Python/ MATLAB/ Machine Learn...</td>\n",
       "      <td>(5 Reviews)</td>\n",
       "      <td>Data Scientist - Python/ MATLAB/ Machine Learn...</td>\n",
       "      <td>IT Skills\\nPython\\nMachine Learning\\nData Scie...</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>IT Skills\\nPython\\nMachine Learning\\nData Scie...</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist -Machine Learning</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Data Scientist -Machine Learning</td>\n",
       "      <td>IT Skills\\nData Science\\nMachine Learning\\nDat...</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine Learning (Commerce BU)</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Data Scientist - Machine Learning (Commerce BU)</td>\n",
       "      <td>Data Science\\nData Enrichment\\nData Scientist\\...</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name_tag  \\\n",
       "0  Data Scientist/Analyst - Machine Learning/Deep...   \n",
       "1  Data Scientist - Python/ MATLAB/ Machine Learn...   \n",
       "2  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "3                   Data Scientist -Machine Learning   \n",
       "4    Data Scientist - Machine Learning (Commerce BU)   \n",
       "\n",
       "                         company_job  \\\n",
       "0                          EchoIndia   \n",
       "1                        (5 Reviews)   \n",
       "2       Wrackle Technologies Pvt Ltd   \n",
       "3       Wrackle Technologies Pvt Ltd   \n",
       "4  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "\n",
       "                                     Designation_job  \\\n",
       "0  Data Scientist/Analyst - Machine Learning/Deep...   \n",
       "1  Data Scientist - Python/ MATLAB/ Machine Learn...   \n",
       "2  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "3                   Data Scientist -Machine Learning   \n",
       "4    Data Scientist - Machine Learning (Commerce BU)   \n",
       "\n",
       "                                           Req_skill    loc_job  \n",
       "0  IT Skills\\nPython\\nMachine Learning\\nTableau\\n...      Delhi  \n",
       "1  IT Skills\\nPython\\nMachine Learning\\nData Scie...  Bengaluru  \n",
       "2  IT Skills\\nPython\\nMachine Learning\\nData Scie...  Bengaluru  \n",
       "3  IT Skills\\nData Science\\nMachine Learning\\nDat...  Bengaluru  \n",
       "4  Data Science\\nData Enrichment\\nData Scientist\\...  Bengaluru  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 9 Scrape the details most watched tv series of all time from imdb.com.\n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Name         Year rating  RunTime  \\\n",
      "0          Game of Thrones  (2011–2019)    9.3   57 min   \n",
      "1                  loading     (2016– )    8.7   51 min   \n",
      "2          Stranger Things     (2010– )    8.2   44 min   \n",
      "3                  loading  (2017–2020)    7.6   60 min   \n",
      "4         The Walking Dead  (2014–2020)    7.6   43 min   \n",
      "..                     ...          ...    ...      ...   \n",
      "95                 loading  (2013–2017)    7.5   42 min   \n",
      "96                New Girl  (2017–2019)    7.8   50 min   \n",
      "97                 loading  (2005–2020)    8.1   42 min   \n",
      "98  Agents of S.H.I.E.L.D.  (2015–2019)    7.2   45 min   \n",
      "99                 loading       (2018)    8.6  572 min   \n",
      "\n",
      "                                     genre  \\\n",
      "0   \\nAction, Adventure, Drama               \n",
      "1     \\nDrama, Fantasy, Horror               \n",
      "2    \\nDrama, Horror, Thriller               \n",
      "3   \\nDrama, Mystery, Thriller               \n",
      "4     \\nDrama, Mystery, Sci-Fi               \n",
      "..                                     ...   \n",
      "95            \\nDrama, Fantasy               \n",
      "96  \\nAdventure, Comedy, Drama               \n",
      "97     \\nCrime, Drama, Mystery               \n",
      "98      \\nCrime, Drama, Horror               \n",
      "99    \\nDrama, Horror, Mystery               \n",
      "\n",
      "                                                votes  \n",
      "0       A|57 min|Action, Adventure, Drama              \n",
      "1                   Stars:Emilia Clarke, Peter Din...  \n",
      "2                                     Votes:1,768,387  \n",
      "3        15|51 min|Drama, Fantasy, Horror              \n",
      "4                   Stars:Millie Bobby Brown, Finn...  \n",
      "..                                                ...  \n",
      "95                                      Votes:333,087  \n",
      "96      16+|45 min|Drama, Fantasy, Horror              \n",
      "97                  Stars:Joseph Morgan, Daniel Gi...  \n",
      "98                                      Votes:117,415  \n",
      "99    12+|43 min|Action, Adventure, Drama              \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def IMDB_top_webseries(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "#Creating empty list to store the data\n",
    "    Name=[]\n",
    "    Year=[]\n",
    "    RunTime=[]\n",
    "    rating=[]\n",
    "    genre=[]\n",
    "    votes=[]\n",
    "#Scraping the all the reqiured details\n",
    "    for i in soup('img'):\n",
    "        Name.append(i.attrs['alt'])\n",
    "    for i in list(soup.find_all('span',attrs={'lister-item-year text-muted unbold'})):\n",
    "        Year.append(i.text)\n",
    "    for i in list(soup.find_all('span',attrs={'runtime'})):\n",
    "        RunTime.append(i.text)\n",
    "    for i in soup.find_all('div',attrs={'ipl-rating-star small'}):\n",
    "        rating.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    for i in list(soup.find_all('span',attrs={'genre'})):\n",
    "        genre.append(i.text)\n",
    "    for i in soup.find_all('p',attrs={'text-muted text-small'}):\n",
    "        votes.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "#Creating DataFrame\n",
    "    df=pd.DataFrame({'Name':Name[0:100],\n",
    "                    'Year':Year[0:100],\n",
    "                    'rating':rating[0:100],\n",
    "                     'RunTime':RunTime[0:100],\n",
    "                    'genre':genre[0:100],\n",
    "                    'votes':votes[0:100]})\n",
    "    print(df)\n",
    "# Calling Function\n",
    "IMDB_top_webseries(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 Scrape the details team India’s international fixtures from bcci.tv. \n",
    "\n",
    "Url = https://www.bcci.tv/.\n",
    "    \n",
    "You need to find following details:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Match title (I.e. 1st ODI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting the webdribver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\91981\\Desktop\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.bcci.tv/international/fixtures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty list to store the scraped the data\n",
    "Match_title=[]\n",
    "Series_title=[]\n",
    "Place_title=[]\n",
    "Date_title=[]\n",
    "Time_title=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INDIA\\nv\\nENGLAND', 'INDIA\\nv\\nENGLAND']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Match Title\n",
    "match=driver.find_elements_by_xpath(\"//div[@class='fixture__teams']\")\n",
    "for i in match:\n",
    "    if i.text is None:\n",
    "        Match_title.append(\"--\")\n",
    "    else:\n",
    "        Match_title.append(i.text)\n",
    "Match_title[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEST', 'TEST']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Series title\n",
    "series=driver.find_elements_by_xpath(\"//div[@class='fixture__format-strip']/span[1]\")\n",
    "for i in series:\n",
    "    if i.text is None:\n",
    "        Series_title.append(\"--\")\n",
    "    else:\n",
    "        Series_title.append(i.text)\n",
    "Series_title[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M. A. Chidambaram Stadium, Chennai', 'Sardar Patel Stadium, Ahmedabad']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Venue of Macth\n",
    "place=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span[1]\")\n",
    "for i in place:\n",
    "    if i.text is None:\n",
    "        Place_title.append(\"--\")\n",
    "    else:\n",
    "        Place_title.append(i.text)\n",
    "Place_title[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13\\nFEBRUARY\\n09:30 IST', '24\\nFEBRUARY\\n14:30 IST']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Date of Macth\n",
    "date=driver.find_elements_by_xpath(\"//div[@class='fixture__full-date']\")\n",
    "for i in date:\n",
    "    if i.text is None:\n",
    "        Date_title.append(\"--\")[0:2]\n",
    "    else:\n",
    "        Date_title.append(i.text)\n",
    "Date_title[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['09:30 IST', '14:30 IST']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Time of match\n",
    "time=driver.find_elements_by_xpath(\"//div[@class='fixture__date-details']/span[2]\")\n",
    "for i in time:\n",
    "    if i.text is None:\n",
    "        Time_title.append(\"--\")\n",
    "    else:\n",
    "        Time_title.append(i.text)\n",
    "Time_title[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the DataFrame\n",
    "Test=pd.DataFrame({'Match_title':Match_title[0:10],'Series_title':Series_title[0:10],'Place_title':Place_title[0:10],\n",
    "                  'Date_title':Date_title[0:10],'Time_title':Time_title[0:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series_title</th>\n",
       "      <th>Place_title</th>\n",
       "      <th>Date_title</th>\n",
       "      <th>Time_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>TEST</td>\n",
       "      <td>M. A. Chidambaram Stadium, Chennai</td>\n",
       "      <td>13\\nFEBRUARY\\n09:30 IST</td>\n",
       "      <td>09:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>TEST</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>24\\nFEBRUARY\\n14:30 IST</td>\n",
       "      <td>14:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>TEST</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>04\\nMARCH\\n09:30 IST</td>\n",
       "      <td>09:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>12\\nMARCH\\n19:00 IST</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>14\\nMARCH\\n19:00 IST</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>16\\nMARCH\\n19:00 IST</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>18\\nMARCH\\n19:00 IST</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>T20I</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>20\\nMARCH\\n19:00 IST</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>ODI</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>23\\nMARCH\\n13:30 IST</td>\n",
       "      <td>13:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>ODI</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>26\\nMARCH\\n13:30 IST</td>\n",
       "      <td>13:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Match_title Series_title  \\\n",
       "0  INDIA\\nv\\nENGLAND         TEST   \n",
       "1  INDIA\\nv\\nENGLAND         TEST   \n",
       "2  INDIA\\nv\\nENGLAND         TEST   \n",
       "3  INDIA\\nv\\nENGLAND         T20I   \n",
       "4  INDIA\\nv\\nENGLAND         T20I   \n",
       "5  INDIA\\nv\\nENGLAND         T20I   \n",
       "6  INDIA\\nv\\nENGLAND         T20I   \n",
       "7  INDIA\\nv\\nENGLAND         T20I   \n",
       "8  INDIA\\nv\\nENGLAND          ODI   \n",
       "9  INDIA\\nv\\nENGLAND          ODI   \n",
       "\n",
       "                                     Place_title               Date_title  \\\n",
       "0             M. A. Chidambaram Stadium, Chennai  13\\nFEBRUARY\\n09:30 IST   \n",
       "1                Sardar Patel Stadium, Ahmedabad  24\\nFEBRUARY\\n14:30 IST   \n",
       "2                Sardar Patel Stadium, Ahmedabad     04\\nMARCH\\n09:30 IST   \n",
       "3                Sardar Patel Stadium, Ahmedabad     12\\nMARCH\\n19:00 IST   \n",
       "4                Sardar Patel Stadium, Ahmedabad     14\\nMARCH\\n19:00 IST   \n",
       "5                Sardar Patel Stadium, Ahmedabad     16\\nMARCH\\n19:00 IST   \n",
       "6                Sardar Patel Stadium, Ahmedabad     18\\nMARCH\\n19:00 IST   \n",
       "7                Sardar Patel Stadium, Ahmedabad     20\\nMARCH\\n19:00 IST   \n",
       "8  Maharashtra Cricket Association Stadium, Pune     23\\nMARCH\\n13:30 IST   \n",
       "9  Maharashtra Cricket Association Stadium, Pune     26\\nMARCH\\n13:30 IST   \n",
       "\n",
       "  Time_title  \n",
       "0  09:30 IST  \n",
       "1  14:30 IST  \n",
       "2  09:30 IST  \n",
       "3  19:00 IST  \n",
       "4  19:00 IST  \n",
       "5  19:00 IST  \n",
       "6  19:00 IST  \n",
       "7  19:00 IST  \n",
       "8  13:30 IST  \n",
       "9  13:30 IST  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 5 Scrape the details of trending repositories on Github.com.\n",
    "\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title         Contri  \\\n",
      "0                                  #start-of-content                  \n",
      "1                                https://github.com/                  \n",
      "2  /join?ref_cta=Sign+up&ref_loc=header+logged+ou...                  \n",
      "3                                          /features                  \n",
      "4                                            /mobile                  \n",
      "5                                  /features/actions       @conwnet   \n",
      "6                               /features/codespaces         @xcv58   \n",
      "7                                 /features/packages  @nodeselector   \n",
      "8                                 /features/security       @kyeotic   \n",
      "9                             /features/code-review/   @bmoore-msft   \n",
      "\n",
      "                                                Lang  \n",
      "0  TypeScript        9,269        202        Buil...  \n",
      "1  PowerShell        9,324        12,224        B...  \n",
      "2  Python        1,109        158        Built by...  \n",
      "3  TypeScript        996        2,646        Buil...  \n",
      "4  JavaScript        27,284        832        Bui...  \n",
      "5  TypeScript        4,607        120        Buil...  \n",
      "6  Go        19,922        2,791        Built by ...  \n",
      "7  Jupyter Notebook        5,022        3,746    ...  \n",
      "8  Jupyter Notebook        349        14        B...  \n",
      "9  TypeScript        818        37        Built b...  \n"
     ]
    }
   ],
   "source": [
    "def Github_Respo(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    #Creating empty list to store the data\n",
    "    Title=[]\n",
    "    Contri=[]\n",
    "    Lang=[]\n",
    "    #Scraping the all the reqiured details\n",
    "    for i in soup('a'):\n",
    "        Title.append(i.attrs['href'])\n",
    "    for i in soup('img'):\n",
    "        Contri.append(i.attrs['alt'])\n",
    "    for i in list(soup.find_all('div',attrs={'f6 text-gray mt-2'})):\n",
    "        Lang.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "  #Creating DataFrame\n",
    "    respo=pd.DataFrame({'Title':Title[0:10],\n",
    "                        'Contri':Contri[0:10],\n",
    "                        'Lang':Lang[0:10]})\n",
    "    print(respo)\n",
    "    \n",
    "Github_Respo(\"https://github.com/trending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 Scrape the details of top 100 songs on billiboard.com.\n",
    "\n",
    "Url = https://www.billiboard.com/\n",
    "    \n",
    "You have to find the following details:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\91981\\Desktop\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.billboard.com/charts/hot-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store the data\n",
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Lastweek_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drivers License', 'Mood']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Song Name \n",
    "song=driver.find_elements_by_xpath(\"//span[@class='chart-element__information']/span[1]\")\n",
    "for i in song:\n",
    "    if i.text is None:\n",
    "        Song_name.append(\"--\")\n",
    "    else:\n",
    "        Song_name.append(i.text)\n",
    "Song_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olivia Rodrigo', '24kGoldn Featuring iann dior']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Artist Name \n",
    "artist=driver.find_elements_by_xpath(\"//span[@class='chart-element__information']/span[2]\")\n",
    "for i in artist:\n",
    "    if i.text is None:\n",
    "        Artist_name.append(\"--\")\n",
    "    else:\n",
    "        Artist_name.append(i.text)\n",
    "Artist_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Last week Rank\n",
    "lastweek=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in lastweek:\n",
    "    if i.text is None:\n",
    "        Lastweek_rank.append(\"--\")\n",
    "    else:\n",
    "        Lastweek_rank.append(i.text)\n",
    "Lastweek_rank[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Peak of Rank\n",
    "peak=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in peak:\n",
    "    if i.text is None:\n",
    "        Peak_rank.append(\"--\")\n",
    "    else:\n",
    "        Peak_rank.append(i.text)\n",
    "Peak_rank[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4', '26']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Weeks of Board\n",
    "weeks=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in weeks:\n",
    "    if i.text is None:\n",
    "        Weeks_board.append(\"--\")\n",
    "    else:\n",
    "        Weeks_board.append(i.text)\n",
    "Weeks_board[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the DataFrame for stored Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs=pd.DataFrame({'Song_name':Song_name[0:100],'Artist_name':Artist_name[0:100],'Lastweek_rank':Lastweek_rank[0:100],\n",
    "                   'Peak_rank':Peak_rank[0:100],'Weeks_board':Weeks_board[0:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Lastweek_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drivers License</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mood</td>\n",
       "      <td>24kGoldn Featuring iann dior</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34+35</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fake Woke</td>\n",
       "      <td>Tom MacDonald</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Prisoner</td>\n",
       "      <td>Miley Cyrus Featuring Dua Lipa</td>\n",
       "      <td>81</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Dangerous</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>-</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Almost Maybes</td>\n",
       "      <td>Jordan Davis</td>\n",
       "      <td>-</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Mr. Right Now</td>\n",
       "      <td>21 Savage &amp; Metro Boomin Featuring Drake</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Song_name                               Artist_name Lastweek_rank  \\\n",
       "0   Drivers License                            Olivia Rodrigo             1   \n",
       "1              Mood              24kGoldn Featuring iann dior             2   \n",
       "2   Blinding Lights                                The Weeknd             3   \n",
       "3             34+35                             Ariana Grande             4   \n",
       "4        Levitating                 Dua Lipa Featuring DaBaby             5   \n",
       "..              ...                                       ...           ...   \n",
       "95        Fake Woke                             Tom MacDonald             -   \n",
       "96         Prisoner            Miley Cyrus Featuring Dua Lipa            81   \n",
       "97        Dangerous                             Morgan Wallen             -   \n",
       "98    Almost Maybes                              Jordan Davis             -   \n",
       "99    Mr. Right Now  21 Savage & Metro Boomin Featuring Drake            80   \n",
       "\n",
       "   Peak_rank Weeks_board  \n",
       "0          1           4  \n",
       "1          1          26  \n",
       "2          1          61  \n",
       "3          2          14  \n",
       "4          5          18  \n",
       "..       ...         ...  \n",
       "95        96           1  \n",
       "96        54          11  \n",
       "97        62           3  \n",
       "98        95           2  \n",
       "99        10          18  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4 Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "\n",
    "Url = http://statisticstimes.com/\n",
    "    \n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\91981\\Desktop\\chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://statisticstimes.com/economy/india/indian-states-gdp.php\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a empty list to store the Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank_tag=[]\n",
    "State_Name=[]\n",
    "GSDP_year=[]\n",
    "GSDP_tag=[]\n",
    "Share_year=[]\n",
    "GDP_billion=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Rank\n",
    "rank=driver.find_elements_by_xpath(\"//td[@class='data1']\")\n",
    "for i in rank:\n",
    "    if i.text is None:\n",
    "        Rank_tag.append(\"--\")\n",
    "    else:\n",
    "        Rank_tag.append(i.text)\n",
    "Rank_tag[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra', 'Uttar Pradesh']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the State Name\n",
    "\n",
    "State=driver.find_elements_by_xpath(\"//td[@class='name']\")\n",
    "for i in State:\n",
    "    if i.text is None:\n",
    "        State_Name.append(\"--\")\n",
    "    else:\n",
    "        State_Name.append(i.text)\n",
    "State_Name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,632,792', '1,668,229']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the GSDP year\n",
    "\n",
    "GSDP=driver.find_elements_by_xpath(\"//td[@class='data sorting_1']\")\n",
    "for i in GSDP:\n",
    "    if i.text is None:\n",
    "        GSDP_year.append(\"--\")\n",
    "    else:\n",
    "        GSDP_year.append(i.text)\n",
    "GSDP_year[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,039,074', '1,215,307']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the GSDP Tag\n",
    "\n",
    "tag=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[8]\")\n",
    "for i in tag:\n",
    "    if i.text is None:\n",
    "        GSDP_tag.append(\"--\")\n",
    "    else:\n",
    "        GSDP_tag.append(i.text)\n",
    "GSDP_tag[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-', '13.88%']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the Share _year\n",
    "share=driver.find_elements_by_xpath(\"//td[@class='data']\")\n",
    "for i in share:\n",
    "    if i.text is None:\n",
    "        Share_year.append(\"--\")\n",
    "    else:\n",
    "        Share_year.append(i.text)\n",
    "Share_year[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['398.145', '246.529']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping the GDP Billion\n",
    "GDP=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[6]\")\n",
    "for i in GDP:\n",
    "    if i.text is None:\n",
    "        GDP_billion.append(\"--\")\n",
    "    else:\n",
    "        GDP_billion.append(i.text)\n",
    "GDP_billion[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP=pd.DataFrame({'Rank_tag':Rank_tag[0:10],'State_Name':State_Name[0:10],\n",
    "                 'GSDP_year':GSDP_year[0:10],'GSDP_tag':GSDP_tag[0:10],\n",
    "                 'Share_year':Share_year[0:10],'GDP_billion':GDP_billion[0:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank_tag</th>\n",
       "      <th>State_Name</th>\n",
       "      <th>GSDP_year</th>\n",
       "      <th>GSDP_tag</th>\n",
       "      <th>Share_year</th>\n",
       "      <th>GDP_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>2,039,074</td>\n",
       "      <td>-</td>\n",
       "      <td>398.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,668,229</td>\n",
       "      <td>1,215,307</td>\n",
       "      <td>13.88%</td>\n",
       "      <td>246.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,186,379</td>\n",
       "      <td>398.145</td>\n",
       "      <td>227.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,544,399</td>\n",
       "      <td>677,428</td>\n",
       "      <td>-</td>\n",
       "      <td>142.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>612,828</td>\n",
       "      <td>2,039,074</td>\n",
       "      <td>130.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>559,412</td>\n",
       "      <td>1,794,508</td>\n",
       "      <td>118.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>531,085</td>\n",
       "      <td>8.79%</td>\n",
       "      <td>111.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>397,669</td>\n",
       "      <td>252.278</td>\n",
       "      <td>79.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>234,048</td>\n",
       "      <td>1,187,277</td>\n",
       "      <td>47.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>224,986</td>\n",
       "      <td>1,137,469</td>\n",
       "      <td>44.945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank_tag      State_Name  GSDP_year   GSDP_tag Share_year GDP_billion\n",
       "0        1     Maharashtra  2,632,792  2,039,074          -     398.145\n",
       "1        2   Uttar Pradesh  1,668,229  1,215,307     13.88%     246.529\n",
       "2        3      Tamil Nadu  1,630,208  1,186,379    398.145     227.276\n",
       "3        4       Karnataka  1,544,399    677,428          -     142.543\n",
       "4        5         Gujarat  1,502,899    612,828  2,039,074     130.210\n",
       "5        6     West Bengal  1,089,898    559,412  1,794,508     118.206\n",
       "6        7       Rajasthan    942,586    531,085      8.79%     111.024\n",
       "7        8  Andhra Pradesh    862,957    397,669    252.278      79.601\n",
       "8        9       Telangana    861,031    234,048  1,187,277      47.769\n",
       "9       10  Madhya Pradesh    809,592    224,986  1,137,469      44.945"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
